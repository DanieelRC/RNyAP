{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtbk1+Oluod8yplItnOaFm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanieelRC/RNyAP/blob/main/Rodriguez_Carreon_Daniel_DescensoPorGradiente.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rodríguez Carreón Daniel        04 de Noviembre de 2025"
      ],
      "metadata": {
        "id": "aS4kpE1DDhWw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "tqCpQ1jCC1B6"
      },
      "outputs": [],
      "source": [
        "# importamos paquetes\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# función de activación\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-x))\n",
        "\n",
        "# Derivada de f\n",
        "def sigmoid_prime(h):\n",
        "    return sigmoid(h) * (1 - sigmoid(h))\n",
        "\n",
        "# clase Neurona\n",
        "class Neurona:\n",
        "    def __init__(self, W, b, activacion):\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.activacion = activacion\n",
        "\n",
        "    def combinacion_lineal(self, X):\n",
        "        h = np.dot(self.W, X) + self.b\n",
        "        return h\n",
        "\n",
        "    def forward(self, X):\n",
        "        h = self.combinacion_lineal(X)\n",
        "        return self.activacion(h)"
      ],
      "metadata": {
        "id": "UJs2kN6pEgUU"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (1 punto): implementar el cálculo del término de error\n",
        "\n",
        "def error_term(y, x, neurona):\n",
        "    h = neurona.combinacion_lineal(x)\n",
        "    return (y - neurona.forward(x)) * sigmoid_prime(h)"
      ],
      "metadata": {
        "id": "CJ-ZP2MrElAm"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (1 punto): implementar el cálculo del incremento\n",
        "def incremento(eta, error_term, X):\n",
        "  return eta * error_term * X"
      ],
      "metadata": {
        "id": "K_JLw4RoIjgt"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO (1 punto): implementar la actualización de los pesos\n",
        "def actualizacion(neurona, incremento_W, incremento_b):\n",
        "    neurona.W += incremento_W\n",
        "    neurona.b += incremento_b\n",
        "    return neurona"
      ],
      "metadata": {
        "id": "14XHy-AcI0Q7"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# valores de ejemplo\n",
        "tasa_aprendizaje = 2.0\n",
        "x = np.array([1, 1])\n",
        "y = 1.0\n",
        "\n",
        "# Valores iniciales de los pesos\n",
        "w = np.array([0.1,0.2])\n",
        "b = 0"
      ],
      "metadata": {
        "id": "V5Td5LWjJK9v"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Calcular la salida de la red\n",
        "neurona = Neurona(w, b, sigmoid)\n",
        "salida = neurona.forward(x)\n",
        "print('Salida:', salida)\n",
        "\n",
        "# ---- Descenso por gradiente ---------------\n",
        "\n",
        "# Calcula el término de error\n",
        "error_t = error_term(y, x, neurona)\n",
        "print('Término de error:', error_t)\n",
        "\n",
        "# Calcula el incremento de los pesos\n",
        "inc_w = incremento(tasa_aprendizaje, error_t, x)\n",
        "print('Incremento:', inc_w)\n",
        "\n",
        "# Calcula el incremento del sesgo\n",
        "inc_b = incremento(tasa_aprendizaje, error_t, 1)\n",
        "print('Incremento del sesgo:', inc_b)\n",
        "\n",
        "# Actualiza los pesos\n",
        "neurona = actualizacion(neurona, inc_w, inc_b)\n",
        "print('Pesos actualizados:', neurona.W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whM9AuGXJQVS",
        "outputId": "a42cc2ab-6f75-42fa-9bb4-ad00fb4b11c1"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salida: 0.574442516811659\n",
            "Término de error: 0.1040310638675848\n",
            "Incremento: [0.20806213 0.20806213]\n",
            "Incremento del sesgo: 0.2080621277351696\n",
            "Pesos actualizados: [0.30806213 0.40806213]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (1 punto) Vuelve a realizar la inferencia y verifica que se está disminuyendo la pérdida.\n",
        "print(\"Término de error incial:\" , error_t)\n",
        "epochs = 20\n",
        "for i in range(epochs):\n",
        "  salida = neurona.forward(x)\n",
        "  print('Salida:', salida)\n",
        "\n",
        "  # ---- Descenso por gradiente ---------------\n",
        "\n",
        "  # Calcula el término de error\n",
        "  error_t = error_term(y, x, neurona)\n",
        "  #print('Término de error:', error_t)\n",
        "\n",
        "  # Calcula el incremento de los pesos\n",
        "  inc_w = incremento(tasa_aprendizaje, error_t, x)\n",
        "  #print('Incremento:', inc_w)\n",
        "\n",
        "  # Calcula el incremento del sesgo\n",
        "  inc_b = incremento(tasa_aprendizaje, error_t, 1)\n",
        "  #print('Incremento del sesgo:', inc_b)\n",
        "\n",
        "  # Actualiza los pesos\n",
        "  neurona = actualizacion(neurona, inc_w, inc_b)\n",
        "  #print('Pesos actualizados:', neurona.W)\n",
        "print(\"Término de error final:\" , error_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFguPi3UKzib",
        "outputId": "cf75225e-c76b-4501-daf9-0720cc070d8a"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Término de error incial: 0.1040310638675848\n",
            "Salida: 0.7158943416659509\n",
            "Salida: 0.7808952782549781\n",
            "Salida: 0.8169504148945351\n",
            "Salida: 0.8402465151628127\n",
            "Salida: 0.8567712408815914\n",
            "Salida: 0.8692319852229005\n",
            "Salida: 0.879039926738775\n",
            "Salida: 0.8870082012975008\n",
            "Salida: 0.8936412288943472\n",
            "Salida: 0.8992700856801074\n",
            "Salida: 0.904121964444198\n",
            "Salida: 0.9083584854545101\n",
            "Salida: 0.9120980897616344\n",
            "Salida: 0.9154297674856064\n",
            "Salida: 0.9184218160929671\n",
            "Salida: 0.9211276200703835\n",
            "Salida: 0.9235895774147451\n",
            "Salida: 0.9258418353145679\n",
            "Salida: 0.9279122388145924\n",
            "Salida: 0.9298237463019267\n",
            "Término de error final: 0.004579109124532411\n"
          ]
        }
      ]
    }
  ]
}